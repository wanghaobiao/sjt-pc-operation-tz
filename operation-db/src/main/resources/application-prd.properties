server.port=1007

spring.datasource.url=jdbc:oracle:thin:@localhost:1521:ORCL
spring.datasource.username=yunying_backend
spring.datasource.password=yunying_backend
spring.jpa.database-platform=org.hibernate.dialect.Oracle10gDialect

spring.datasource.db2.url=jdbc:mysql://47.97.19.179:3306/sjt?useUnicode=true&characterEncoding=UTF-8&useSSL=false&allowPublicKeyRetrieval=true&serverTimezone=Asia/Shanghai
spring.datasource.db2.username=sjt
spring.datasource.db2.password=Qwe@123`!
spring.datasource.db2.driver-class-name=com.mysql.cj.jdbc.Driver


spring.jpa.hibernate.ddl-auto=none
logging..level.org.springframework.jdbc.core.JdbcTemplate = DEBUG

#swagger配置
config.swagger.show=true
config.aes.issecurity=false
config.aes.skey=YWNyYWJzb2Z0Y29tMTIz
config.aes.iv=MTIzNDU2Nzg5MDEyMzQ1Ng==
config.security.escpe_urls=swagger,api-docs,error,swagger,authorize,html

#licens配置
config.license.type=license3j
config.license.licPath=E:\\license\\aclicense.license
config.license.pubPath=E:\\license\\acrabsoftPublicCerts.store
config.license.publicalias=publiccert
config.license.storepwd=xmzx123
config.license.subject=acrabsoft

###########【Kafka集群】###########
#spring.kafka.bootstrap-servconsumerers=master:9092,slave2:9092,slave1:9092
spring.kafka.bootstrap-servers=20.45.16.51:9092,20.45.16.73:9092,20.45.16.86:9092
spring.kafka.listeners=PLAINTEXT://20.45.16.51:9092
spring.kafka.metrics-recording-level = INFO
###########【初始化生产者配置】###########
# 重试次数
spring.kafka.producer.retries=3
# 应答级别:多少个分区副本备份完成时向生产者发送ack确认(可选0、1、all/-1)
spring.kafka.producer.acks=1
# 批量大小
spring.kafka.producer.batch-size=16384
# 提交延时
spring.kafka.producer.properties.linger.ms=0
# 当生产端积累的消息达到batch-size或接收到消息linger.ms后,生产者就会将消息提交给kafka
# linger.ms为0表示每接收到一条消息就提交给kafka,这时候batch-size其实就没用了

# 生产端缓冲区大小
spring.kafka.producer.buffer-memory = 33554432
# Kafka提供的序列化和反序列化类
spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.value-serializer=org.apache.kafka.common.serialization.StringSerializer
# 自定义分区器
# spring.kafka.producer.properties.partitioner.class=com.felix.kafka.producer.CustomizePartitioner

###########【初始化消费者配置】###########
# 默认的消费组ID
spring.kafka.consumer.properties.group.id=kafka-producer
# 是否自动提交offset
spring.kafka.consumer.enable-auto-commit=true
# 提交offset延时(接收到消息后多久提交offset)
spring.kafka.consumer.auto-commit-interval-ms=1000

# 当kafka中没有初始offset或offset超出范围时将自动重置offset
# earliest:重置为分区中最小的offset;
# latest:重置为分区中最新的offset(消费分区中新产生的数据);
# none:只要有一个分区不存在已提交的offset,就抛出异常;
spring.kafka.consumer.auto-offset-reset=latest
# 消费会话超时时间(超过这个时间consumer没有发送心跳,就会触发rebalance操作)
spring.kafka.consumer.properties.session.timeout.ms=120000
# 消费请求超时时间
spring.kafka.consumer.properties.request.timeout.ms=180000
# Kafka提供的序列化和反序列化类
spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer
# 消费端监听的topic不存在时，项目启动会报错(关掉)
spring.kafka.listener.missing-topics-fatal=false
# 设置批量消费
# spring.kafka.listener.type=batch
# 批量消费每次最多消费多少条消息
spring.kafka.consumer.max-poll-records=50

#hbase
hbase.zookeeper.quorum=master,slave1,slave2
hbase.zookeeper.property.clientPort=2181
zookeeper.znode.parent=/hbase

#hive
spring.datasource.hive.url=jdbc:hive2://master:10000/default
spring.datasource.hive.type=com.alibaba.druid.pool.DruidDataSource
spring.datasource.hive.username=root
spring.datasource.hive.password=123456
spring.datasource.hive.driver-class-name=org.apache.hive.jdbc.HiveDriver
spring.datasource.common-config.initialSize=1

spring.datasource.common-config.minIdle=1
spring.datasource.common-config.maxIdle=5
spring.datasource.common-config.maxActive=50
spring.datasource.common-config.maxWait=10000
spring.datasource.common-config.timeBetweenEvictionRunsMillis=10000
spring.datasource.common-config.minEvictableIdleTimeMillis=300000
spring.datasource.common-config.validationQuery=select 'x'
spring.datasource.common-config.testWhileIdle=true
spring.datasource.common-config.testOnBorrow=false
spring.datasource.common-config.testOnReturn=false
spring.datasource.common-config.poolPreparedStatements=true
spring.datasource.common-config.maxOpenPreparedStatements=20
spring.datasource.common-config.filters=stat

huawei.kafka.configs.folder=E:\\IdeaSpace_ZxMy\\sjt-pc-operation\\src\\main\\resources\\kafka\\
hbase.config.path=E:\\IdeaSpace_ZxMy\\sjt-pc-operation\\src\\main\\resources\\kafka\\

#用户 1  zazd_dsj
#用户 2  zazd_xmzx
huaweiUser=zazd_xmzx
hbaseUser=sjt

ftp.ip=50.16.195.244
ftp.port=21
ftp.username=vsftp_user
ftp.password=qwe@123
zip.encode=F6BEE4DF8759421187B68FCD5B407166
ftp.read.count=3

hbase.spache=zazd_xmzx:
#地市
area=3200
get.hbase.num.url=http://50.16.195.244:1007/operation/system/sequence/getHbaseNum
#"3205","苏州市"  "3208","淮安市" "3201","南京市"  "3200","省厅应用"
queue.length=1000

file.url=http://122.51.121.254:30002/wjfw/v1.0.0/file/download/